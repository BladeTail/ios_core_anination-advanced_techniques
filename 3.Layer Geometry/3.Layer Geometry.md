
# 图层几何

<i>**对几何一无所知者，禁止入内。**</i>

<i>Let no one unversed in geometry enter here.</i>

——柏拉图学院入口标语

第二章，“背景图片”介绍了以图层layer背景图片，以及在layer的范围内用来控制位置和缩放的一些属性。在本章中，我们来看一下图层layer是如何与其上层图层和同级图层之间，是如何进行位置摆放和大小设置的。我们也会探讨如何管理图层几何，以及自适应大小和自动布局对它的影响。

## 布局

UIView有三个基本的布局属性：frame，bounds和center。CALayer也有与之等价的三个属性，分别是：frame，bounds和position。至于为什么layer上叫做position而view上叫做center后面会说明白，但是它们代表的值的意思都是一样的。

frame属性表示layer的外部坐标系（即layer占据的上层图层空间位置），bounds属性则是其内部的坐标系（通常使用layer的左上角作为{0，0}坐标原点，但也并非所有的都是这样的），而center和position都表示其相对于上层图层的锚点坐标。anchorPoint在后面会介绍，目前就把它当作是layer的中心点。如图3.1展示的是view和layer这些相关属性：

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.1.png?raw=true)

frame属性并不是一个一成不变的属性，他是一个根据bounds，position和transform计算得到的虚拟属性，这也就意味着，当其他这几个属性发生变化时，frame属性也会随之变化。反过来，修改frame的时候，其他几个对应属性的值也会发生变化。当你在进行处理transform（变形）的时候就要特别注意这一点，因为图层layer在旋转或者缩放时，被变形的layer的frame属性映射了在父对象中占据的整个轴向位置的矩形区域，也就是说它的宽度和高度不再和它的bonds属性相匹配了（如图3.2）。

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.2.png?raw=true)

### anchorPoint

如前面提到过的，view的center和layer的position属性都是代表其相对于父层的锚点坐标。layer的anchorPoint控制着layer的frame相对于position属性的摆放位置。你可以将anchorPoint想像成layer进行移动时需要的一个操作把手。

默认情况下，anchorPoint位于layer的中心位置，所以layer都是以其中心点为把手进行摆放的，不管它被摆放在哪里。UIView的接口并没有暴露anchorPoint属性，所以为什么视图对象的位置属性叫做“center”，但是layer的anchorPoint是可以进行修改的。比如，你可以将其改到图层layer的frame的左上角，这样的话，图层的内容就会从它的position向下和向右进行展开，而不是从它的中心点（如图3.3）。

和第2章中说的contentsRect和contentsCenter一样，anchorPoint使用的是单位坐标系，也就意味着它的坐标系和图层的大小是相对应的。左上角的坐标为{0,0}，右下角的坐标为{1,1}。默认情况下（center）position属性的值为{0.5,0.5}。锚点也可以在layer的取悦范围之外，指定其x或y的值小于0或者大于1就行了。

注意图3.3中，修改anchorPoint时，position保持不变，而layer的frame发生改变。

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.3.png?raw=true)

那么，我们为什么要修改anchorPoint呢？如果我们已经可以随意摆放frame，那还要修改anchorPoint，不就反而给人造成疑惑吗？要展示这个为什么有用，我们先来做一个实践性的例子。我们来创建一个带有时、分、秒指针的模拟时钟界面。

该界面由四张图片构成（如图3.4）。简单起见，我们以传统的方式，分别使用四个不同的UIImageView实例对象，直接加载并显示这些图片（我们本来是应该使用正常的UIView对象并设置其layer的contents属性的）。

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.4.png?raw=true)

时钟的组件直接在InterfaceBuilder中进行排版（如图3.5）。图片的视图相互之间进行嵌套，并且都禁用了自适应大小和布局。这是因为自适应大小是在视图view的frame中进行的，如图3.2所展示的，一旦view被旋转其frame就会发生变化，当被旋转的view的frame大小发生变化时，会导致其布局出现故障。

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.5.png?raw=true)

我们将会使用NSTimer来更新我们的时钟，并使用视图view的transform属性来旋转这几个时间的指针。（如果你对这个属性还不熟悉，那也没关系，在第5章“变形”中我们会涵盖进去。）代码清单3.1展示了时钟的代码。

Listing 3.1 Clock
```objectivec
@interface ViewController ()

@property (nonatomic, weak) IBOutlet UIImageView *hourHand;
@property (nonatomic, weak) IBOutlet UIImageView *minuteHand;
@property (nonatomic, weak) IBOutlet UIImageView *secondHand;
@property (nonatomic, weak) NSTimer *timer;

@end

@implementation ViewController

- (void)viewDidLoad {
    [super viewDidLoad];
    //start timer
    self.timer = [NSTimer scheduledTimerWithTimeInterval:1.0 target:self selector:@selector(tick) userInfo:nil repeats:YES];
    //set initial hand positions
    [self tick];
}

- (void)tick {
    //convert time to hours, minutes and seconds
    NSCalendar *calendar = [[NSCalendar alloc] initWithCalendarIdentifier:NSGregorianCalendar];
    NSUInteger units = NSHourCalendarUnit | NSMinuteCalendarUnit | NSSecondCalendarUnit;
    NSDateComponents *components = [calendar components:units fromDate:[NSDate date]];
    //calculate hour hand angle
    CGFloat hoursAngle = (components.hour / 12.0) * M_PI * 2.0;

    //calculate minute hand angle
    CGFloat minsAngle = (components.minute / 60.0) * M_PI * 2.0;
    //calculate second hand angle
    CGFloat secsAngle = (components.second / 60.0) * M_PI * 2.0;
    //rotate hands
    self.hourHand.transform = CGAffineTransformMakeRotation(hoursAngle);
    self.minuteHand.transform = CGAffineTransformMakeRotation(minsAngle);
    self.secondHand.transform = CGAffineTransformMakeRotation(secsAngle);
}

@end

```

当我们运行此APP是会发现有些奇怪（如图3.6）。因为这些指针图片都是以其中心点为圆心进行旋转的，但是我们所预期的显然并不是这样的。

你可能觉得，在Interface Builder中，通过调整指针图片的位置可以解决这个问题，然而这也是无用功，因为如果图片的中心位置不在时钟界面的中心位置的话，连旋转都不对。

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.6.png?raw=true)

有一种解决方案是在指针图片的底部添加透明的空间（也就使其中心点向我们预期的地方移动），但是这样做就是的图片比实际需要的要大，而且会消耗更多的内存，这种做法当然不够优雅。

更好的办法是使用其anchorPoint属性。我们可以在`viewDidLoad`加一点额外的代码,把这些指针图片的锚点向下移动（代码清单3.2）。如图3.7，我们的“时钟”就是很正常了。

Listing 3.1 Clock
```objectivec
- (void)viewDidLoad {
  [super viewDidLoad];
  //adjust anchor points
  self.secondHand.layer.anchorPoint = CGPointMake(0.5f, 0.9f);
  self.minuteHand.layer.anchorPoint = CGPointMake(0.5f, 0.9f);
  self.hourHand.layer.anchorPoint = CGPointMake(0.5f, 0.9f);
  //start timer
  ...
}
```

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.7.png?raw=true)

### 坐标系

图层和视图对象一样，也是树状结构排版的，在图层树中，每一个图层都是与其上一层的父级图层相对进行摆放的。图层的position属性是相对于其上层父级图层的bounds相对应的，一旦其父级图层移动了，底下的所有图层也都会被移动。

在对图层的位置进行处理的时候，这样就会很方便，因为我们可以将某个父级图层作为根图层进行移动，从而将其相关的整个树状图层作为一个单元进行移动。但是呢，有时候我们又需要知道某个图层的绝对位置，或者更常见的，我们需要知道该图层和其他图层的相对位置，而不是其直接父图层中所处的位置。

CALayer提供了几种使用的方法来转换不同图层坐标系之间的转换：
```objectivec
- (CGPoint)convertPoint:(CGPoint)point fromLayer:(CALayer *)layer;
- (CGPoint)convertPoint:(CGPoint)point toLayer:(CALayer *)layer;
- (CGRect)convertRect:(CGRect)rect fromLayer:(CALayer *)layer;
- (CGRect)convertRect:(CGRect)rect toLayer:(CALayer *)layer;
```
这些方法可以让我们将某个图层上一个点（CGPoint）或者一个矩形（CGRect）区域，转换到另外一个图层的坐标系中去。

### 翻转的几何

通常来讲，iOS中图层layer的position指的是相对于其父级图层bounds区域的左上角的位置，而在Mac OS中，却是是相对于其左下角。Core Animation同时支持这两种设定，通过指定`geometryFlipped`属性的值就可以了。这个属性是个BOOL类型的值,它的作用是决定当前图层layer对象是否关于其父级图层垂直翻转。如果将此属性设置为YES，也就意味垂直翻转此layer，使其position指定为相对于其父图层的左下角的位置，而默认的是左上角（正常情况下，其子图层还是左上角，除非你把这些子图层的`geometryFlipped`属性值也设置为YES）。

### Z轴

UIView严格来讲是二维的，和它不一样的是，CALayer是三维的。除了我们已经讨论过的position和anchorPoint之外，CALayer还有另外两个属性，zPosition和anchorPointZ，两个都是浮点数值类型，也都是关于其Z轴的属性描述。

注意，bounds除了宽度属性width和高度属性height之外，可并没有深度depth属性。图层仅仅只是一个基础的平面对象。你可以认为它们有点类似于纸张一样的纯二维性质的平面面板，但是它们可以相互粘合形成空洞一样的折叠式的3D结构体。

大部分情况下属性zPosition都没有什么特别的用处。在第5章中，我们将探索CATransform3D，我们就会看到在三维空间中如何移动和旋转这些图层。如果不使用“变形”的话，可能zPosition属性的唯一用处就是改变图层layer的显示顺序了。

通常，图层都是按照在父级图层的sublayers属性中出现的顺序进行绘制的。这也就是我们所熟知的“画家算法”，因为像画家画一面墙一样，后画出来的图层会掩盖掉先画出来的图层。但是通过增加图层的zPosition的值，你可以将其向上拉，使其更靠近“摄像头”，从而在物理上使其位于其他图层的前面（至少，要比那些zPosition值更小的靠前一些吧）。

这个“摄像头”也就是我们所指的用户的视角了，这个和iPhone手机内置的背部摄像头可没有任何关系（尽管其背部的摄像头的方向和用户的视角方向一致，但是这都是巧合而已）。

图3.8展示的就是在Interface Builder中两个视图的摆放示例。如你所见，先拖进去的那个绿色的视图，绘制在后拖进去的红色视图的下面。

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.8.png?raw=true)

我们还期望真实的APP中也是这样的，但是如果我们增加绿色视图的zPosition的值的话（代码清单3.3），顺序就反过来了（如图3.9）。注意我们并不需要增大很多，视图对象的厚度是无限小的，所以即使zPosition仅仅只是增加一个点，也会使绿色视图比红色的更靠前。更小的值比如0.1或者0.0001都行，但是不要使用太小的值，因为浮点的四舍五入的近似计算过程出问题的话就会导致视觉上的问题。

Listing 3.3 Adjusting zPosition to Change the Display Order
```objectivec
@interface ViewController ()
@property (nonatomic, weak) IBOutlet UIView *greenView;
@property (nonatomic, weak) IBOutlet UIView *redView;
@end
@implementation ViewController
- (void)viewDidLoad {
      [super viewDidLoad];

      //move the green view zPosition nearer to the camera
      self.greenView.layer.zPosition = 1.0f;
}
@end
```

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.9.png?raw=true)

### Hit Testing
第1章“图层树”开始的时候就提到过，通常我们会更倾向于使用具有背景图层的视图，而不是构建单独的图层树，其中一个原因就是使用图层来处理触摸事件的时候会及其复杂。

CALayer对“响应链”一无所知，所以它并不能直接处理触摸事件或者手势操作。不过它也的确有一些方法来辅助我们处理触摸事件：`-containsPoint:` 和 `-hitTest:`。

方法`-containsPoint:`接收一个当前图层坐标系下的CGPoint类型的参数，如果这个点位于此图层的frame内部，就反回YES。代码清单3.4所展示的是和第1章的项目所适配的代码样例，使用此方法来判断，到底是白色的图层还是蓝色的图层被触摸了（如图3.10）。将触摸点在两个图层的坐标系中转换来转换去，看上去就有点奇奇怪怪的。

Listing 3.4 Determining the Touched Layer Using containsPoint:
```objectivec
@interface ViewController ()

@property (nonatomic, weak) IBOutlet UIView *layerView;
@property (nonatomic, weak) CALayer *blueLayer;

@end

@implementation ViewController
- (void)viewDidLoad {
    [super viewDidLoad];
    //create sublayer
    self.blueLayer = [CALayer layer];
    self.blueLayer.frame = CGRectMake(50.0f, 50.0f, 100.0f, 100.0f);
    self.blueLayer.backgroundColor = [UIColor blueColor].CGColor;
    //add it to our view
    [self.layerView.layer addSublayer:self.blueLayer];
}

- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event {
    //get touch position relative to main view
    CGPoint point = [[touches anyObject] locationInView:self.view];
    //convert point to the white layer's coordinates
    point = [self.layerView.layer convertPoint:point fromLayer:self.view.layer];
    //get layer using containsPoint:
    if ([self.layerView.layer containsPoint:point]) {
        //convert point to blueLayer’s coordinates
        point = [self.blueLayer convertPoint:point fromLayer:self.layerView.layer];
        if ([self.blueLayer containsPoint:point]){
            [[[UIAlertView alloc] initWithTitle:@"Inside Blue Layer" message:nil delegate:nil cancelButtonTitle:@"OK" otherButtonTitles:nil] show];
        }
        else{
            [[[UIAlertView alloc] initWithTitle:@"Inside White Layer" message:nil delegate:nil cancelButtonTitle:@"OK" otherButtonTitles:nil] show];
        }
    }
}
@end
```

![](https://github.com/BladeTail/ios_core_anination-advanced_techniques/blob/master/3.Layer%20Geometry/3.10.png?raw=true)

方法`-hitTest:`同样也接受一个CGPoint的参数，但是返回的不是BOOL值，而是一个包含这个点的最底层的CALayer对象，这个对象要么是当前图层layer，要么是此图层最底部的包含这个点子图层。也就是说你不需要像使用`-containsPoint:`一样，自己把这个点坐标在图层坐标系之间转换来转换去。如果这个点位于当前图层之外，就会返回nil。代码清单3.5就是使用`-hitTest:`的例子。

Listing 3.5 Determining the Touched Layer Using hitTest:
```objectivec
- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event{
    //get touch position
    CGPoint point = [[touches anyObject] locationInView:self.view];
    //get touched layer
    CALayer *layer = [self.layerView.layer hitTest:point];
    //get layer using hitTest
    if (layer == self.blueLayer){
        [[[UIAlertView alloc] initWithTitle:@"Inside Blue Layer" message:nil delegate:nil cancelButtonTitle:@"OK" otherButtonTitles:nil] show];
    }
    else if (layer == self.layerView.layer) {
        [[[UIAlertView alloc] initWithTitle:@"Inside White Layer" message:nil delegate:nil cancelButtonTitle:@"OK" otherButtonTitles:nil] show];
    }
}
```
需要注意的是，使用图层的`-hitTest:`的话，测试调用的顺序严格地基于图层树中各个图层的加入顺序（巧得很，UIView的触摸处理也是这样的）。前面我们说过的zPosition只是改变了屏幕上显示的顺序，但是并不会改变图层加入到图层树中的顺序，所以也就不会改变触摸事件处理的顺序。

这也就意味着，如果你改变了图层的Z值，可能就会出现无法检测显示在屏幕最外侧的图层的触摸事件了，因为它被先加入到图层树中、只是Z值小而显示在下面的图层所拦截掉了。在第5章中，我们会更详细地讨论这个问题。

### 自动布局

你可能已经接触过`UIViewAutoresizingMask`的内容，它是用来控制UIView父视图发生变化时其frame属性刷新的（通常这是用来处理屏幕在横屏和竖屏之间翻转的）。

在iOS6中，苹果公司介绍过自动布局的机制。指定constraints约束相比于自适应大小的方式很不一样，而且要更加复杂，它们结合在一起，形成了一个线性的等式以及非线性的系统，从而来定义视图对象的位置和大小。

在Mac OS中，CALayer有一个叫做`layoutManager`的属性，可以让你使用`CALayoutManager`的非正式协议和`CAConstraintLayoutManager`类来充分利用自动布局的机制。但是因为某些原因，iOS里用不了。

当使用基于图层的视图对象时，你可以充分利用UIView接口暴露出来的API，如`UIViewAutoresizingMask`和`NSLayoutConstraint`。但是如果你想控制任意的CALayer的布局的话，你就得手工控制了。最简单的方法就是使用CALayerDelegate的方法：
```objectivec
- (void)layoutSublayersOfLayer:(CALayer *)layer;
```
一旦图层layer的bounds发生变化或者其方法`-setNeedsLayout`被调用，这个方法就会被自动触发。这样就给了开发者一个自行编程来处理其子图层对象位置和大小的机会，但是却不会像UIView的autoresizingMask和constraints属性一样，在屏幕旋转之后，还提供了自动的默认行为来维持图层的布局。

## 总结

本章所涵盖的CALayer几何问题，包括它的frame，position和bounds，我们还了解了图层是存在于三维空间的概念，而不是二维平面的。我们还讨论了基于纯图层的触摸事件的处理实现，以及Core Animation在iOS中，在自适应大小和自动布局上的缺陷和不足。

第4章“视觉效果”中，我们将探讨一下Core Animation里图层的视觉特性。
